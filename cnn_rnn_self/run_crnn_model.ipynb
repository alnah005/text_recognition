{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danny/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import argparse\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell\n",
    "\n",
    "# from .decoding import get_words_from_chars\n",
    "# from .config import Params, CONST\n",
    "# from src.model import crnn_fn\n",
    "# from src.data_handler import data_loader\n",
    "# from src.data_handler import preprocess_image_for_prediction\n",
    "\n",
    "# from src.config import Params, Alphabet, import_params_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains information for the actual network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_train = \"/home/danny/Repos/text_recognition/tf-crnn-master/data/train.csv\"\n",
    "csv_files_eval = \"/home/danny/Repos/text_recognition/tf-crnn-master//data/valid.csv\"\n",
    "output_model_dir = \"/home/danny/Repos/text_recognition/tf-crnn-master/estimator\"\n",
    "n_epochs = 5\n",
    "gpu = \"\" # help=\"GPU 0,1 or '' \", default=''\n",
    "\n",
    "train_batch_size=64\n",
    "eval_batch_size=64\n",
    "learning_rate=1e-3  # 1e-3 recommended\n",
    "learning_decay_rate=0.95\n",
    "learning_decay_steps=5000\n",
    "evaluate_every_epoch=5\n",
    "save_interval=5e3\n",
    "input_shape=(117, 1669)\n",
    "optimizer='adam'\n",
    "digits_only=False\n",
    "alphabet=\" !\\\"#&'()*+,-./0123456789:;<=>?ABCDEFGHIJKLMNOPQRSTUVWXY[]_abcdefghijklmnopqrstuvwxyz|£§àâèéê⊥\"\n",
    "alphabet_decoding='same'\n",
    "alphabet_codes = list(range(len(alphabet)))\n",
    "n_classes = len(alphabet)\n",
    "csv_delimiter='\\t'\n",
    "\n",
    "# seems to be about gpu usage, which isn't relevant to me\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = parameters.gpu\n",
    "# config_sess = tf.ConfigProto()\n",
    "# config_sess.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "# config_sess.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the estimator (including the model, below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stuff below likely not necessary\n",
    "\n",
    "# # Config estimator\n",
    "# est_config = tf.estimator.RunConfig()\n",
    "# est_config.replace(keep_checkpoint_max=10,\n",
    "#                    save_checkpoints_steps=parameters.save_interval,\n",
    "#                    session_config=config_sess,\n",
    "#                    save_checkpoints_secs=None,\n",
    "#                    save_summary_steps=1000,\n",
    "#                    model_dir=parameters.output_model_dir)\n",
    "\n",
    "# estimator = tf.estimator.Estimator(model_fn=crnn_fn,\n",
    "#                                    params=model_params,\n",
    "#                                    model_dir=parameters.output_model_dir,\n",
    "#                                    config=est_config\n",
    "#                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Count number of image filenames in csv\n",
    "# n_samples = 0\n",
    "# with open(csv_files_eval, 'r', encoding='utf8') as csvfile:\n",
    "#     reader = csv.reader(csvfile, delimiter=parameters.csv_delimiter)\n",
    "#     n_samples += len(list(reader))\n",
    "    \n",
    "    \n",
    "# try:\n",
    "#     for e in trange(0, parameters.n_epochs, parameters.evaluate_every_epoch):\n",
    "#         estimator.train(input_fn=data_loader(csv_filename=parameters.csv_files_train,\n",
    "#                                              params=parameters,\n",
    "#                                              batch_size=parameters.train_batch_size,\n",
    "#                                              num_epochs=parameters.evaluate_every_epoch,\n",
    "#                                              data_augmentation=True,\n",
    "#                                              image_summaries=True))\n",
    "#         estimator.evaluate(input_fn=data_loader(csv_filename=parameters.csv_files_eval,\n",
    "#                                                 params=parameters,\n",
    "#                                                 batch_size=parameters.eval_batch_size,\n",
    "#                                                 num_epochs=1),\n",
    "#                            steps=np.floor(n_samples/parameters.eval_batch_size)\n",
    "#                            )\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     print('Interrupted')\n",
    "#     estimator.export_savedmodel(os.path.join(parameters.output_model_dir, 'export'),\n",
    "#                                 preprocess_image_for_prediction(min_width=10))\n",
    "#     print('Exported model to {}'.format(os.path.join(parameters.output_model_dir, 'export')))\n",
    "\n",
    "# estimator.export_savedmodel(os.path.join(parameters.output_model_dir, 'export'),\n",
    "#                             preprocess_image_for_prediction(min_width=10))\n",
    "# print('Exported model to {}'.format(os.path.join(parameters.output_model_dir, 'export')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# needed for quickly making convolutional layers\n",
    "def weightVar(shape, mean=0.0, stddev=0.02, name='weights'):\n",
    "    init_w = tf.truncated_normal(shape=shape, mean=mean, stddev=stddev)\n",
    "    return tf.Variable(init_w, name=name)\n",
    "\n",
    "\n",
    "def biasVar(shape, value=0.0, name='bias'):\n",
    "    init_b = tf.constant(value=value, shape=shape)\n",
    "    return tf.Variable(init_b, name=name)\n",
    "\n",
    "\n",
    "def conv2d(input, filter, strides=[1, 1, 1, 1], padding='SAME', name=None):\n",
    "    return tf.nn.conv2d(input, filter, strides=strides, padding=padding, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n:param features: dict {\\n                        'images'\\n                        'images_widths'\\n                        'filenames'\\n                        }\\n:param labels: labels. flattend (1D) array with encoded label (one code per character)\\n:param mode:\\n:param params: dict {\\n                        'Params'\\n                    }\\n:return:\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    ":param features: dict {\n",
    "                        'images'\n",
    "                        'images_widths'\n",
    "                        'filenames'\n",
    "                        }\n",
    ":param labels: labels. flattend (1D) array with encoded label (one code per character)\n",
    ":param mode:\n",
    ":param params: dict {\n",
    "                        'Params'\n",
    "                    }\n",
    ":return:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob_dropout = 0.7\n",
    "#input_tensor = features['images']\n",
    "input_tensor = tf.placeholder(tf.float32, [None, input_shape[0], input_shape[1], 1])\n",
    "labels = tf.placeholder(tf.string, [None])\n",
    "is_training = True\n",
    "\n",
    "if input_tensor.shape[-1] == 1:\n",
    "    input_channels = 1\n",
    "elif input_tensor.shape[-1] == 3:\n",
    "    input_channels = 3\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('deep_cnn'):\n",
    "    # conv1 - maxPool2x2\n",
    "    with tf.variable_scope('layer1'):\n",
    "        W = weightVar([3, 3, input_channels, 64])\n",
    "        b = biasVar([64])\n",
    "        conv = conv2d(input_tensor, W, name='conv')\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        conv1 = tf.nn.relu(out)\n",
    "        pool1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                               padding='SAME', name='pool')\n",
    "\n",
    "    # conv2 - maxPool 2x2\n",
    "    with tf.variable_scope('layer2'):\n",
    "        W = weightVar([3, 3, 64, 128])\n",
    "        b = biasVar([128])\n",
    "        conv = conv2d(pool1, W)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        conv2 = tf.nn.relu(out)\n",
    "        pool2 = tf.nn.max_pool(conv2, [1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                               padding='SAME', name='pool1')\n",
    "\n",
    "    # conv3 - w/batch-norm (as source code, not paper)\n",
    "    with tf.variable_scope('layer3'):\n",
    "        W = weightVar([3, 3, 128, 256])\n",
    "        b = biasVar([256])\n",
    "        conv = conv2d(pool2, W)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        b_norm = tf.layers.batch_normalization(out, axis=-1,\n",
    "                                               training=is_training, name='batch-norm')\n",
    "        conv3 = tf.nn.relu(b_norm, name='ReLU')\n",
    "\n",
    "    # conv4 - maxPool 2x1\n",
    "    with tf.variable_scope('layer4'):\n",
    "        W = weightVar([3, 3, 256, 256])\n",
    "        b = biasVar([256])\n",
    "        conv = conv2d(conv3, W)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        conv4 = tf.nn.relu(out)\n",
    "        pool4 = tf.nn.max_pool(conv4, [1, 2, 2, 1], strides=[1, 2, 1, 1],\n",
    "                               padding='SAME', name='pool4')\n",
    "\n",
    "    # conv5 - w/batch-norm\n",
    "    with tf.variable_scope('layer5'):\n",
    "        W = weightVar([3, 3, 256, 512])\n",
    "        b = biasVar([512])\n",
    "        conv = conv2d(pool4, W)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        b_norm = tf.layers.batch_normalization(out, axis=-1,\n",
    "                                               training=is_training, name='batch-norm')\n",
    "        conv5 = tf.nn.relu(b_norm)\n",
    "\n",
    "    # conv6 - maxPool 2x1 (as source code, not paper)\n",
    "    with tf.variable_scope('layer6'):\n",
    "        W = weightVar([3, 3, 512, 512])\n",
    "        b = biasVar([512])\n",
    "        conv = conv2d(conv5, W)\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        conv6 = tf.nn.relu(out)\n",
    "        pool6 = tf.nn.max_pool(conv6, [1, 2, 2, 1], strides=[1, 2, 1, 1],\n",
    "                               padding='SAME', name='pool6')\n",
    "\n",
    "    # conv 7 - w/batch-norm (as source code, not paper)\n",
    "    with tf.variable_scope('layer7'):\n",
    "        W = weightVar([2, 2, 512, 512])\n",
    "        b = biasVar([512])\n",
    "        conv = conv2d(pool6, W, padding='VALID')\n",
    "        out = tf.nn.bias_add(conv, b)\n",
    "        b_norm = tf.layers.batch_normalization(out, axis=-1,\n",
    "                                               training=is_training, name='batch-norm')\n",
    "        conv7 = tf.nn.relu(b_norm)\n",
    "\n",
    "    # reshape output\n",
    "    with tf.variable_scope('Reshaping_cnn'):\n",
    "        shape = conv7.get_shape().as_list()  # [batch, height, width, features]\n",
    "        shape_tens = tf.shape(conv7)\n",
    "        transposed = tf.transpose(conv7, perm=[0, 2, 1, 3],\n",
    "                                  name='transposed')  # [batch, width, height, features]\n",
    "        conv_out = tf.reshape(transposed, [shape_tens[0], -1, shape[1] * shape[3]],\n",
    "                                   name='reshaped')  # [batch, width, height x features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logprob, raw_pred = deep_bidirectional_lstm(conv, params=parameters, summaries=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def deep_bidirectional_lstm(inputs: tf.Tensor, params: Params, summaries: bool=True) -> tf.Tensor:\n",
    "# Prepare data shape to match `bidirectional_rnn` function requirements\n",
    "# Current data input shape: (batch_size, n_steps, n_input) \"(batch, time, height)\"\n",
    "\n",
    "list_n_hidden = [256, 256]\n",
    "\n",
    "with tf.name_scope('deep_bidirectional_lstm'):\n",
    "    # Forward direction cells\n",
    "    fw_cell_list = [BasicLSTMCell(nh, forget_bias=1.0) for nh in list_n_hidden]\n",
    "    # Backward direction cells\n",
    "    bw_cell_list = [BasicLSTMCell(nh, forget_bias=1.0) for nh in list_n_hidden]\n",
    "\n",
    "    lstm_net, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(fw_cell_list,\n",
    "                                                                    bw_cell_list,\n",
    "                                                                    conv_out, # THE INPUT\n",
    "                                                                    dtype=tf.float32\n",
    "                                                                    )\n",
    "\n",
    "    # Dropout layer\n",
    "    lstm_net = tf.nn.dropout(lstm_net, keep_prob=keep_prob_dropout)\n",
    "\n",
    "    with tf.variable_scope('Reshaping_rnn'):\n",
    "        shape = lstm_net.get_shape().as_list()  # [batch, width, 2*n_hidden]\n",
    "        rnn_reshaped = tf.reshape(lstm_net, [-1, shape[-1]])  # [batch x width, 2*n_hidden]\n",
    "\n",
    "    with tf.variable_scope('fully_connected'):\n",
    "        W = weightVar([list_n_hidden[-1]*2, n_classes])\n",
    "        b = biasVar([n_classes])\n",
    "        fc_out = tf.nn.bias_add(tf.matmul(rnn_reshaped, W), b)\n",
    "\n",
    "    shape_tens = tf.shape(lstm_net)\n",
    "    lstm_out = tf.reshape(fc_out, [shape_tens[0], -1, n_classes], name='reshape_out')  # [batch, width, n_classes]\n",
    "\n",
    "    raw_pred = tf.argmax(tf.nn.softmax(lstm_out), axis=2, name='raw_prediction')\n",
    "\n",
    "    # Swap batch and time axis\n",
    "    lstm_out = tf.transpose(lstm_out, [1, 0, 2], name='transpose_time_major')  # [width(time), batch, n_classes]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine CNN and LSTM and create training op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for loss and training\n",
    "\n",
    "# Compute seq_len from image width\n",
    "n_pools = 2*2  # 2x2 pooling in dimension W on layer 1 and 2\n",
    "seq_len_inputs = tf.divide([input_shape[1]]*train_batch_size, n_pools,\n",
    "                           name='seq_len_input_op') - 1\n",
    "\n",
    "predictions_dict = {'prob': lstm_out,\n",
    "                    'raw_predictions': raw_pred,\n",
    "                    }\n",
    "\n",
    "\n",
    "# Get keys (letters) and values (integer stand ins for letters)\n",
    "# Alphabet and codes\n",
    "keys = [c for c in alphabet] # the letters themselves\n",
    "values = alphabet_codes # integer representations\n",
    "\n",
    "\n",
    "# Create non-string labels from the keys and values above\n",
    "# Convert string label to code label\n",
    "with tf.name_scope('str2code_conversion'):\n",
    "    table_str2int = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(keys, values), -1)\n",
    "    splited = tf.string_split(labels, delimiter='')  # TODO change string split to utf8 split in next tf version\n",
    "    codes = table_str2int.lookup(splited.values)\n",
    "    sparse_code_target = tf.SparseTensor(splited.indices, codes, splited.dense_shape)\n",
    "\n",
    "seq_lengths_labels = tf.bincount(tf.cast(sparse_code_target.indices[:, 0], tf.int32),\n",
    "                                 minlength=tf.shape(predictions_dict['prob'])[1])\n",
    "\n",
    "\n",
    "# Use ctc loss on probabilities from lstm output\n",
    "# Loss\n",
    "# ----\n",
    "# >>> Cannot have longer labels than predictions -> error\n",
    "with tf.control_dependencies([tf.less_equal(sparse_code_target.dense_shape[1], tf.reduce_max(tf.cast(seq_len_inputs, tf.int64)))]):\n",
    "    loss_ctc = tf.nn.ctc_loss(labels=sparse_code_target,\n",
    "                              inputs=predictions_dict['prob'],\n",
    "                              sequence_length=tf.cast(seq_len_inputs, tf.int32),\n",
    "                              preprocess_collapse_repeated=False,\n",
    "                              ctc_merge_repeated=True,\n",
    "                              ignore_longer_outputs_than_inputs=True,  # returns zero gradient in case it happens -> ema loss = NaN\n",
    "                              time_major=True)\n",
    "    loss_ctc = tf.reduce_mean(loss_ctc)\n",
    "    loss_ctc = tf.Print(loss_ctc, [loss_ctc], message='* Loss : ')\n",
    "\n",
    "    \n",
    "# Create the learning rate as well as a moving average\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "# # Create an ExponentialMovingAverage object\n",
    "ema = tf.train.ExponentialMovingAverage(decay=0.99, num_updates=global_step, zero_debias=True)\n",
    "# Create the shadow variables, and add op to maintain moving averages\n",
    "maintain_averages_op = ema.apply([loss_ctc])\n",
    "loss_ema = ema.average(loss_ctc)\n",
    "\n",
    "# Train op\n",
    "# --------\n",
    "learning_rate = tf.train.exponential_decay(learning_rate, global_step,\n",
    "                                           learning_decay_steps, learning_decay_rate,\n",
    "                                           staircase=True)\n",
    "\n",
    "\n",
    "# Set up optimizer\n",
    "if optimizer == 'ada':\n",
    "    optimizer = tf.train.AdadeltaOptimizer(learning_rate)\n",
    "elif optimizer == 'adam':\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "elif optimizer == 'rms':\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "opt_op = optimizer.minimize(loss_ctc, global_step=global_step)\n",
    "with tf.control_dependencies(update_ops + [opt_op]):\n",
    "    train_op = tf.group(maintain_averages_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the details to make all images the same size\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from skimage import io as skimio\n",
    "from skimage import color as skimcolor\n",
    "import skimage.transform as skimtrans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "local_path = \"/home/danny/Repos/text_recognition/tf-crnn-master/\"\n",
    "img_dir = \"data/Images_mod/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/train.csv\", \"r\") as f:\n",
    "    train_inf = [l.split(\"\\t\") for l in f.read().splitlines()]\n",
    "    for i in range(len(train_inf)):\n",
    "        train_inf[i][1] = train_inf[i][1][1:-1]\n",
    "\n",
    "train_data = []\n",
    "for i in range(len(train_inf)):\n",
    "    X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # writer = tf.summary.FileWriter('./my_graph/LogRegNormal', sess.graph)\n",
    "    n_batches = int(mnist.train.num_examples / train_batch_size)\n",
    "    for i in range(n_epochs):  # train the model training_steps times\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(train_batch_size)\n",
    "            tr_batch = sess.run(train_op, feed_dict={X: X_batch, Y: Y_batch})\n",
    "            \n",
    "        print('epoch: {0}, loss: {1}'.format(i, tr_batch))\n",
    "\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('Optimization Finished!') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# load data\n",
    "mnist = input_data.read_data_sets('/data/mnist', one_hot=True)\n",
    "\n",
    "# set learning parameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "training_steps = 1500\n",
    "training_display = 500\n",
    "\n",
    "# LSTM parameters\n",
    "hidden_size = 200\n",
    "n_classes = 10\n",
    "\n",
    "# create placeholders for features and labels\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28]) # treat it as 28x28 vector\n",
    "Y = tf.placeholder(tf.int32, [None, 10])\n",
    "\n",
    "# create weights and bias\n",
    "w = tf.Variable(tf.zeros([hidden_size, 10]))\n",
    "b = tf.Variable(tf.zeros([n_classes]))\n",
    "\n",
    "# create LSTM layer\n",
    "little_x = tf.unstack(X, 28, 1)\n",
    "lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=1.0)\n",
    "outputs, states = rnn.static_rnn(lstm_cell, little_x, dtype=tf.float32)\n",
    "logits = tf.matmul(outputs[-1], w) + b\n",
    "\n",
    "# loss function\n",
    "soft = tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = logits)\n",
    "loss = tf.reduce_mean(soft)\n",
    "\n",
    "# training op\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# model evaluation\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))  \n",
    "\n",
    "\n",
    "# run optimization\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # writer = tf.summary.FileWriter('./my_graph/LogRegNormal', sess.graph)\n",
    "    n_batches = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(training_steps):  # train the model training_steps times\n",
    "        X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "        X_batch = X_batch.reshape((batch_size, 28, 28))\n",
    "        sess.run(optimizer, feed_dict={X: X_batch, Y: Y_batch})\n",
    "        if i % training_display == 0:\n",
    "            loss_batch, acc_batch = sess.run([loss, accuracy], feed_dict={X: X_batch,\n",
    "                                                                            Y: Y_batch})\n",
    "            acc_batch2 = acc_batch / batch_size\n",
    "            print('step: {0}, loss: {1}, accuracy: {2}'.format(i, loss_batch, acc_batch2))\n",
    "\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "    print('Optimization Finished!') \n",
    "\n",
    "    # test the final model\n",
    "    n_batches = int(mnist.test.num_examples / batch_size)\n",
    "    total_correct_preds = 0\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "        X_batch = X_batch.reshape((batch_size, 28, 28))\n",
    "        accuracy_batch = sess.run(accuracy, feed_dict={X: X_batch, Y: Y_batch})\n",
    "        total_correct_preds += accuracy_batch\n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds / mnist.test.num_examples))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
